#!/bin/bash

# Merge per interval VCFs into a GVCF
# Samples are gzipped and tabix indexed

# Job resources
# 6 samples:
# Requested: 48 CPU 192 Gb mem, 2:30:00
# Used: 48 CPU, 113.3 Gb, 0:32:95 walltime (2:50:55 CPU time). (~20Gb mem per sample)
# 1CPU 4Gb mem sufficient for hm82 samples

#PBS -P hm82
#PBS -N pon_gathervcfs
#PBS -l walltime=01:00:00,ncpus=48,mem=192GB,wd
#PBS -q normal
#PBS -W umask=022
#PBS -l storage=scratch/er01+scratch/hm82+scratch/public
#PBS -o ./Logs/gatk4_pon_gathervcfs/pon_gathervcfs.o
#PBS -e ./Logs/gatk4_pon_gathervcfs/pon_gathervcfs.e

module load openmpi/4.0.2
module load nci-parallel/1.0.0

set -e

NCPUS=1 # CPUs per task

# SCRIPT
SCRIPT=./gatk4_pon_gathervcfs.sh
INPUTS=./Inputs/gatk4_pon_gathervcfs.inputs

echo "$(date): GATK4 GatherVcfs."


#########################################################
# Do not edit below this line
#########################################################

if [[ $PBS_QUEUE =~ bw-exec ]]; then CPN=28; else CPN=48; fi

M=$(( CPN / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / CPN)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file



